```{r}
# Task 2: Import Libraries
library(tidyverse)
library(readxl)
library(h2o)
library(lime)
library(recipes) 
```

```{r}
# Task 2.1: Load the IBM Employee Attrition Data
hr_data_raw <- read_csv("HR-Employee-Attrition.csv")
hr_data_raw[1:10,]
```


```{r}
# Task 3: Pre-process Data Using Recipes
# Convert character type columns to factors
hr_data <- hr_data_raw %>%
  mutate_if(is.character, as.factor) %>%
  select(Attrition, everything())

# Standardize numerical columns - recipe
recipe_obj <- hr_data %>%
  recipe(formula = Attrition ~ .) %>%  # specify formula
  step_rm(EmployeeNumber) %>% # remove columns
  step_zv(all_predictors()) %>% # remove constant columns from predictors
  step_center(all_numeric()) %>% # center data zero mean
  step_scale(all_numeric()) %>% # set std = 1
  prep(data = hr_data)

# Bake new data set as specified above
hr_data <- bake(recipe_obj, new_data = hr_data)
glimpse(hr_data)

```


```{r}
# Task 4.0: Start H2O Cluster and Create Train/Test Splits
h2o.init(max_mem_size = "4g")

```

```{r}
# Task 4.1: Create Training and Test Sets









```

```{r}
# Task 5: Run AutoML to Train and Tune Models









```

```{r}
# Task 6: Leaderboard Exploration



#model_ids <-as.data.frame(aml@leaderboard$model_id)[,1]
#best_model <- h2o.getModel(grep("StackedEnsemble_BestOfFamily", model_ids, value=TRUE)[1])
```



```{r}
# Task 7: Model Performance Evaluation




```


```{r}
# Task 9: Local Interpretable Model-Agnostic Explanations 








```



