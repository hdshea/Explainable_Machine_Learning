```{r}
# Task 2: Import Libraries
library(tidyverse)
library(readxl)
library(h2o)
library(lime)
library(recipes) 
```

```{r}
# Task 2.1: Load the IBM Employee Attrition Data
hr_data_raw <- read_csv("HR-Employee-Attrition.csv")
hr_data_raw[1:10,]
```

```{r}
# Task 3: Pre-process Data Using Recipes
# Convert character type columns to factors
hr_data <- hr_data_raw %>%
  mutate_if(is.character, as.factor) %>%
  select(Attrition, everything())

# Standardize numerical columns - recipe
recipe_obj <- hr_data %>%
  recipe(formula = Attrition ~ .) %>%  # specify formula
  step_rm(EmployeeNumber) %>% # remove columns
  step_zv(all_predictors()) %>% # remove constant columns from predictors
  step_center(all_numeric()) %>% # center data zero mean
  step_scale(all_numeric()) %>% # set std = 1
  prep(data = hr_data)

# Bake new data set as specified above
hr_data <- bake(recipe_obj, new_data = hr_data)
glimpse(hr_data)
```

```{r}
# Task 4.0: Start H2O Cluster and Create Train/Test Splits
h2o.init(max_mem_size = "4g")
```

```{r}
# Task 4.1: Create Training and Test Sets
set.seed(1234)
hr_data_h2o <- as.h2o(hr_data)

splits <- h2o.splitFrame(hr_data_h2o, c(0.7, 0.15), seed = 1234)

train <- h2o.assign(splits[[1]], "train")
valid <- h2o.assign(splits[[2]], "valid")
test <- h2o.assign(splits[[3]], "test")
```

```{r}
# Task 5: Run AutoML to Train and Tune Models
y <- "Attrition"
x <- setdiff(names(train), y)

aml <- h2o.automl(x = x,
                  y = y,
                  training_frame = train,
                  leaderboard_frame = valid,
                  max_runtime_secs = 60)
```

```{r}
# Task 6: Leaderboard Exploration
lb <- aml@leaderboard
print(lb, n = nrow(lb))

# since we want to use StackedEnsemble_BestOfFamily assign this way rather than 
# best_model <- aml@leader
model_ids <-as.data.frame(aml@leaderboard$model_id)[,1]
best_model <- h2o.getModel(grep("StackedEnsemble_BestOfFamily", model_ids, value=TRUE)[1])
```

```{r}
# Task 7: Model Performance Evaluation
perf <- h2o.performance(best_model, newdata = test)
optimal_threshold <- h2o.find_threshold_by_max_metric(perf, "f1")
metrics <- as.data.frame(h2o.metric(perf, optimal_threshold))
t(metrics)
# compare accuracy vs precision and recall
# here null_error_rate is lower than accuracy
# null_error_rate <- metrics$tns / (metrics$tps + metrics$tns + metrics$fps + metrics$fns)
# recall <- tps / (tps + fns)
```

### LIME Technical Details

Get the slides from course notes for tech details on LIME.

Attrition:  the models created predict the likelihood of an employee leaving - they don't reveal the
reasons that drive attrition, however.  And that is what the company cares about.  Model
interpretations (which is what LIME helps with) helps to get at those reasons - the underlying
business drivers of attrition.

```{r}
# Task 9: Local Interpretable Model-Agnostic Explanations 
# use data without Attrition [, -31]
explainer <- lime(as.data.frame(train[, -31]), best_model, bin_continuous = FALSE) 
explanation <- explain(as.data.frame(test[3:10, -31]),
                      explainer = explainer,
                      kernel_width = 1,
                      n_features = 5,
                      n_labels = 1)

plot_features(explanation)
```



